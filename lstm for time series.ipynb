{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "RNN-1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikpy/EconometricsSem3/blob/master/lstm%20for%20time%20series.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2pai4I9WeJu"
      },
      "source": [
        "#Stock Market Prediction by Recurrent Neural Network on LSTM Model\n",
        "\n",
        "The prediction of the market value is of great importance to help in maximizing the profit of stock option purchase while keeping the risk low. Recurrent neural networks (RNN) have proved one of the most powerful models for processing sequential data. Long Short-Term memory is one of the most successful RNNs architectures. LSTM introduces the memory cell, a unit of computation that replaces traditional artificial neurons in the hidden layer of the network. With these memory cells, networks are able to effectively associate memories and input remote in time, hence suit to grasp the structure of data dynamically over time with high prediction capacity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RXVvI-5WNzA"
      },
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMpv3eBWZlXQ"
      },
      "source": [
        "Stage 1: Raw Data: In this stage, the historical stock data is collected from the Google stock price and this historical data is used for the prediction of future stock prices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPzM5dFkWNzH"
      },
      "source": [
        "!wget http://upscfever.com/upsc-fever/en/data/images/Google_Stock_Price_Train.csv -P drive/app\n",
        "dataset = pd.read_csv('drive/app/Google_Stock_Price_Train.csv',index_col=\"Date\",parse_dates=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIW3b570WNzJ"
      },
      "source": [
        "dataset.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II0Yw6QfWNzN"
      },
      "source": [
        "dataset.isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bArteWwyWNzP"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKH3P8UlWNzR"
      },
      "source": [
        "dataset['Open'].plot(figsize=(16,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjpOYTstWNzU"
      },
      "source": [
        "# convert column \"a\" of a DataFrame\n",
        "dataset[\"Close\"] = dataset[\"Close\"].str.replace(',', '').astype(float)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3maeYOUWNzX"
      },
      "source": [
        "dataset[\"Volume\"] = dataset[\"Volume\"].str.replace(',', '').astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP6cWidlWNzZ"
      },
      "source": [
        "# 7 day rolling mean\n",
        "dataset.rolling(7).mean().head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1QoRg8aWNzb"
      },
      "source": [
        "dataset['Open'].plot(figsize=(16,6))\n",
        "dataset.rolling(window=30).mean()['Close'].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iYsi-JEWNze"
      },
      "source": [
        "dataset['Close: 30 Day Mean'] = dataset['Close'].rolling(window=30).mean()\n",
        "dataset[['Close','Close: 30 Day Mean']].plot(figsize=(16,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXZkEsqaWNzg"
      },
      "source": [
        "# Optional specify a minimum number of periods\n",
        "dataset['Close'].expanding(min_periods=1).mean().plot(figsize=(16,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4jcOmM0WNzj"
      },
      "source": [
        "training_set=dataset['Open']\n",
        "training_set=pd.DataFrame(training_set)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3MTa1DDZo0H"
      },
      "source": [
        "Stage 2: Data Preprocessing: The pre-processing stage involves a) Data discretization: Part of data reduction but with particular importance, especially for numerical data b) Data transformation: Normalization. c) Data cleaning: Fill in missing values. d) Data integration: Integration of data files. After the dataset is transformed into a clean dataset, the dataset is divided into training and testing sets so as to evaluate. Creating a data structure with 60 timesteps and 1 output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjjkPoPMWNzl"
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "training_set_scaled = sc.fit_transform(training_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVCE0sHEWNzo"
      },
      "source": [
        "# Creating a data structure with 60 timesteps and 1 output\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(60, 1258):\n",
        "    X_train.append(training_set_scaled[i-60:i, 0])\n",
        "    y_train.append(training_set_scaled[i, 0])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "\n",
        "# Reshaping\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "475XhEwHZ6_4"
      },
      "source": [
        "Feature Extraction: In this layer, only the features which are to be fed to the neural network are chosen. We will choose the feature from Date, open, high, low, close, and volume."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DK6OIrjWNzq"
      },
      "source": [
        "# Part 2 - Building the RNN\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keUiQZuXWNzs"
      },
      "source": [
        "# Initialising the RNN\n",
        "regressor = Sequential()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE1OGbwsaAHh"
      },
      "source": [
        "Stage 4: Training Neural Network: In this stage, the data is fed to the neural network and trained for prediction assigning random biases and weights. Our LSTM model is composed of a sequential input layer followed by 3 LSTM layers and dense layer with activation and then finally a dense output layer with linear activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhv50f29WNzw"
      },
      "source": [
        "# Adding the first LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a second LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a third LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a fourth LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding the output layer\n",
        "regressor.add(Dense(units = 1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1g0B0A_WNzy"
      },
      "source": [
        "# Compiling the RNN\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "# Fitting the RNN to the Training set\n",
        "regressor.fit(X_train, y_train, epochs = 10, batch_size = 32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv-7te4AWNz1"
      },
      "source": [
        "# Part 3 - Making the predictions and visualising the results\n",
        "!wget http://upscfever.com/upsc-fever/en/data/images/Google_Stock_Price_Test.csv -P drive/app\n",
        "# Getting the real stock price of 2017\n",
        "dataset_test = pd.read_csv('drive/app/Google_Stock_Price_Test.csv',index_col=\"Date\",parse_dates=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dTfO1HTWNz4"
      },
      "source": [
        "real_stock_price = dataset_test.iloc[:, 1:2].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffNEaDNiWNz8"
      },
      "source": [
        "dataset_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-8St1j7WNz_"
      },
      "source": [
        "dataset_test.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBuE8Id2WN0B"
      },
      "source": [
        "dataset_test[\"Volume\"] = dataset_test[\"Volume\"].str.replace(',', '').astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3d4dnB2WN0D"
      },
      "source": [
        "test_set=dataset_test['Open']\n",
        "test_set=pd.DataFrame(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaFqiXRWWN0H"
      },
      "source": [
        "test_set.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbDejfPzWN0K"
      },
      "source": [
        "# Getting the predicted stock price of 2017\n",
        "dataset_total = pd.concat((dataset['Open'], dataset_test['Open']), axis = 0)\n",
        "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
        "inputs = inputs.reshape(-1,1)\n",
        "inputs = sc.transform(inputs)\n",
        "X_test = []\n",
        "for i in range(60, 80):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "predicted_stock_price = regressor.predict(X_test)\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE6O4vk2WN0L"
      },
      "source": [
        "predicted_stock_price=pd.DataFrame(predicted_stock_price)\n",
        "predicted_stock_price.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVJlpWR5WN0O"
      },
      "source": [
        "\n",
        "# Visualising the results\n",
        "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
        "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
        "plt.title('Google Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Google Stock Price')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}